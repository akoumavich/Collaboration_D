{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from HiggsML.ingestion import Ingestion\n",
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join('sample_code_submission', 'model.py'))\n",
    "sys.path.append(os.path.join('sample_code_submission', 'neural_network.py'))\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory is /Users/neosapien/Development/Collaboration_D\n"
     ]
    }
   ],
   "source": [
    "TEST_SETTINGS = {\n",
    "\"systematics\": {  # Systematics to use\n",
    "    \"tes\": False, # tau energy scale\n",
    "    \"jes\": False, # jet energy scale\n",
    "    \"soft_met\": False, # soft term in MET\n",
    "    \"w_scale\": False, # W boson scale factor\n",
    "    \"bkg_scale\": False, # Background scale factor\n",
    "    },\n",
    "\"num_pseudo_experiments\" : 10 , # Number of pseudo-experiments to run per set\n",
    "\"num_of_sets\" : 2, # Number of sets of pseudo-experiments to run\n",
    "}\n",
    "\n",
    "USE_RANDOM_MUS = True\n",
    "\n",
    "root_dir = \"../\"\n",
    "print(\"Root directory is\", os.path.abspath(root_dir))\n",
    "\n",
    "input_dir = os.path.join(root_dir, \"public_data\", \"input_data\")\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "if USE_RANDOM_MUS:\n",
    "    test_settings[ \"ground_truth_mus\"] = (np.random.uniform(0.1, 3, test_settings[\"num_of_sets\"])).tolist()\n",
    "    \n",
    "    random_settings_file = os.path.join(output_dir, \"random_mu.json\")\n",
    "    with open(random_settings_file, \"w\") as f:\n",
    "        json.dump(test_settings, f)\n",
    "else:\n",
    "    test_settings_file = os.path.join(input_dir, \"test\", \"settings\", \"data.json\")\n",
    "    with open(test_settings_file) as f:\n",
    "        test_settings = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing to whether to use the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PUBLIC_DATASET = False\n",
    "\n",
    "if USE_PUBLIC_DATASET:\n",
    "    from HiggsML.datasets import BlackSwan_public_dataset as public_dataset\n",
    "    data = public_dataset()\n",
    "else:\n",
    "    from HiggsML.datasets import Data\n",
    "    data = Data(input_dir, data_format=\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading Train data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5090511 entries, 0 to 5090510\n",
      "Columns: 16 entries, PRI_lep_pt to PRI_met_phi\n",
      "dtypes: float32(16)\n",
      "memory usage: 310.7 MB\n",
      "None\n",
      "[*] Train data loaded successfully\n",
      "[*] Initializing Submmited Model\n",
      "[*] Loading Train data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5090511 entries, 0 to 5090510\n",
      "Columns: 16 entries, PRI_lep_pt to PRI_met_phi\n",
      "dtypes: float32(16)\n",
      "memory usage: 310.7 MB\n",
      "None\n",
      "[*] Train data loaded successfully\n",
      "Full data:  (5090511, 16)\n",
      "Full Labels:  (5090511,)\n",
      "Full Weights:  (5090511,)\n",
      "sum_signal_weights:  3639.000000000001\n",
      "sum_bkg_weights:  3743369.999999998\n",
      " \n",
      " \n",
      "Training Data:  (3770937, 16)\n",
      "Training Labels:  (3770937,)\n",
      "Training Weights:  (3770937,)\n",
      "sum_signal_weights:  3639.0000000000005\n",
      "sum_bkg_weights:  3743369.9999999935\n",
      "\n",
      "Valid Data:  (1527153, 16)\n",
      "Valid Labels:  (1527153,)\n",
      "Valid Weights:  (1527153,)\n",
      "sum_signal_weights:  3639.0000000000036\n",
      "sum_bkg_weights:  3743369.9999999977\n",
      " \n",
      " \n",
      "feature engineering took 2.37 s, results:\n",
      "\n",
      "         PRI_lep_pt   PRI_lep_eta   PRI_lep_phi    PRI_had_pt   PRI_had_eta  \\\n",
      "count  3.770937e+06  3.770937e+06  3.770937e+06  3.770937e+06  3.770937e+06   \n",
      "mean   4.003678e+01  1.822653e-04  1.700528e-03  5.060574e+01 -3.370857e-04   \n",
      "std    2.391138e+01  1.173671e+00  1.813139e+00  2.761748e+01  1.203677e+00   \n",
      "min    2.000000e+01 -2.500000e+00 -3.142000e+00  2.287600e+01 -2.688000e+00   \n",
      "25%    2.583300e+01 -8.920000e-01 -1.569000e+00  3.388700e+01 -9.250000e-01   \n",
      "50%    3.331600e+01  0.000000e+00  2.000000e-03  4.432100e+01 -1.000000e-03   \n",
      "75%    4.544400e+01  8.920000e-01  1.573000e+00  5.822100e+01  9.240000e-01   \n",
      "max    1.190700e+03  2.500000e+00  3.142000e+00  1.260630e+03  2.728000e+00   \n",
      "\n",
      "        PRI_had_phi  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
      "count  3.770937e+06        3.770937e+06         3.770937e+06   \n",
      "mean  -6.044020e-05        7.442527e+01        -6.816989e-04   \n",
      "std    1.813358e+00        5.839309e+01         1.549073e+00   \n",
      "min   -3.142000e+00        2.287800e+01        -4.962000e+00   \n",
      "25%   -1.570000e+00        4.107400e+01        -1.116000e+00   \n",
      "50%    0.000000e+00        5.536500e+01        -2.000000e-03   \n",
      "75%    1.569000e+00        8.354800e+01         1.115000e+00   \n",
      "max    3.142000e+00        1.509400e+03         4.962000e+00   \n",
      "\n",
      "       PRI_jet_leading_phi    PRI_n_jets  ...  DER_mass_transverse_met_lep  \\\n",
      "count         3.770937e+06  3.770937e+06  ...                 3.770937e+06   \n",
      "mean         -6.586051e-04  1.658039e+00  ...                 2.637269e+01   \n",
      "std           1.812961e+00  4.743668e-01  ...                 3.015930e+01   \n",
      "min          -3.142000e+00  1.000000e+00  ...                -7.000000e+00   \n",
      "25%          -1.573000e+00  1.000000e+00  ...                 6.674157e+00   \n",
      "50%          -1.000000e-03  2.000000e+00  ...                 1.687271e+01   \n",
      "75%           1.571000e+00  2.000000e+00  ...                 3.666925e+01   \n",
      "max           3.142000e+00  2.000000e+00  ...                 1.850061e+03   \n",
      "\n",
      "       DER_mass_jet_jet  DER_deltaeta_jet_jet    DER_sum_pt  \\\n",
      "count      3.770937e+06          3.770937e+06  3.770937e+06   \n",
      "mean       2.210097e+01         -1.063590e+00  1.650669e+02   \n",
      "std        3.964044e+01          4.434808e+00  8.840524e+01   \n",
      "min       -7.000000e+00         -7.000000e+00  6.379700e+01   \n",
      "25%       -7.000000e+00         -7.000000e+00  1.127920e+02   \n",
      "50%        1.327205e+01          8.110000e-01  1.409690e+02   \n",
      "75%        3.169973e+01          2.290000e+00  1.830300e+02   \n",
      "max        8.774383e+02          8.034000e+00  3.580430e+03   \n",
      "\n",
      "       DER_met_phi_centrality  DER_prodeta_jet_jet  DER_deltar_tau_lep  \\\n",
      "count            3.770937e+06         3.770937e+06        3.770937e+06   \n",
      "mean             4.096358e-01        -2.394480e+00        2.943782e+00   \n",
      "std              1.139682e+00         4.146789e+00        9.491113e-01   \n",
      "min             -7.000000e+00        -1.536365e+01        3.538037e-01   \n",
      "25%             -9.963400e-01        -7.000000e+00        2.386124e+00   \n",
      "50%              1.058635e+00        -1.580850e+00        3.084621e+00   \n",
      "75%              1.371356e+00         4.995000e-01        3.473093e+00   \n",
      "max              1.414214e+00         1.501122e+01        7.615928e+00   \n",
      "\n",
      "       DER_lep_eta_centrality  DER_pt_ratio_lep_tau    DER_pt_tot  \n",
      "count            3.770937e+06          3.770937e+06  3.770937e+06  \n",
      "mean            -2.139201e+00          9.298275e-01  2.897051e+02  \n",
      "std              3.517547e+00          6.607403e-01  3.605976e+02  \n",
      "min             -7.000000e+00          1.588174e-02  3.952063e+01  \n",
      "25%             -7.000000e+00          5.399459e-01  1.064965e+02  \n",
      "50%              6.503730e-04          7.683811e-01  1.702599e+02  \n",
      "75%              5.246181e-01          1.106355e+00  3.083743e+02  \n",
      "max              1.000000e+00          2.812246e+01  6.075179e+03  \n",
      "\n",
      "[8 rows x 28 columns]\n",
      "\n",
      "Training Data:  (3770937, 28)\n",
      "Using device:  mps\n",
      "Model is NN\n",
      "[*] Calling fit method of submitted model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneosapien17\u001b[0m (\u001b[33manonx\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/neosapien/Development/Collaboration_D/sample_code_submission/wandb/run-20240607_105527-x80685lr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anonx/higgsml/runs/x80685lr' target=\"_blank\">vague-plant-29</a></strong> to <a href='https://wandb.ai/anonx/higgsml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anonx/higgsml' target=\"_blank\">https://wandb.ai/anonx/higgsml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anonx/higgsml/runs/x80685lr' target=\"_blank\">https://wandb.ai/anonx/higgsml/runs/x80685lr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Training Accuracy:  0.8505257446624008\n",
      "Saving model to ../ckpts/model-1.pth with accuracy: 0.8505257446624008 at epoch 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 47 is out of bounds for axis 0 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ingestion\u001b[38;5;241m.\u001b[39minit_submission(Model)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# if you truly want to train, change the epochs to a reasonable number in neural_network.py\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/HiggsML/ingestion.py:70\u001b[0m, in \u001b[0;36mIngestion.fit_submission\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_submission\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[*] Calling fit method of submitted model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/Collaboration_D/sample_code_submission/model.py:169\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m balanced_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m weights_train\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(balanced_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m], balanced_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m], balanced_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_info \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_saved_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m train_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    172\u001b[0m train_results \u001b[38;5;241m=\u001b[39m compute_mu(train_score, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_info)\n",
      "File \u001b[0;32m~/Development/Collaboration_D/sample_code_submission/statistical_analysis.py:210\u001b[0m, in \u001b[0;36mcalculate_saved_info\u001b[0;34m(model, train_set)\u001b[0m\n\u001b[1;32m    207\u001b[0m     histo_plot(score, train_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m], n)\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nS, nB, pS, pB, wS, wB\n\u001b[0;32m--> 210\u001b[0m Proba_et_Poids \u001b[38;5;241m=\u001b[39m \u001b[43mProba_hist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_set, Proba_et_Poids\n",
      "File \u001b[0;32m~/Development/Collaboration_D/sample_code_submission/statistical_analysis.py:159\u001b[0m, in \u001b[0;36mcalculate_saved_info.<locals>.Proba_hist\u001b[0;34m(n, model, train_set)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(score)):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m         \u001b[43mwS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m         wB[\u001b[38;5;28mround\u001b[39m((n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m score[i])] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 47 is out of bounds for axis 0 with size 25"
     ]
    }
   ],
   "source": [
    "data.load_train_set()\n",
    "ingestion = Ingestion(data)\n",
    "ingestion.init_submission(Model)\n",
    "# if you truly want to train, change the epochs to a reasonable number in neural_network.py\n",
    "ingestion.fit_submission()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
