{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Starting Kit - Black Swan HiggsML Course\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "`COLAB` determines whether this notebook is running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    ! git clone https://github.com/blackSwanCS/Collaboration_D \n",
    "    %cd Collaboration_D\n",
    "\n",
    "# HiggsML utility package should not be modified\n",
    "%pip install HiggsML\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Settings\n",
    "The Test setting sets the test conditions in ingestion.\n",
    "This includes what systematics you want and how many psuedo experiments you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "\"systematics\": {  # Systematics to use\n",
    "    \"tes\": False, # tau energy scale\n",
    "    \"jes\": False, # jet energy scale\n",
    "    \"soft_met\": False, # soft term in MET\n",
    "    \"w_scale\": False, # W boson scale factor\n",
    "    \"bkg_scale\": False, # Background scale factor\n",
    "    },\n",
    "\"num_pseudo_experiments\" : 10 , # Number of pseudo-experiments to run per set\n",
    "\"num_of_sets\" : 2, # Number of sets of pseudo-experiments to run\n",
    "} \n",
    "\n",
    "USE_RANDOM_MUS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "\n",
    "input_dir = os.path.join(root_dir, \"sample_data\")\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "if USE_RANDOM_MUS:\n",
    "    test_settings[ \"ground_truth_mus\"] = (np.random.uniform(0.1, 3, test_settings[\"num_of_sets\"])).tolist()\n",
    "    \n",
    "    random_settings_file = os.path.join(output_dir, \"random_mu.json\")\n",
    "    with open(random_settings_file, \"w\") as f:\n",
    "        json.dump(test_settings, f)\n",
    "else:\n",
    "    test_settings_file = os.path.join(input_dir, \"test\", \"settings\", \"data.json\")\n",
    "    with open(test_settings_file) as f:\n",
    "        test_settings = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Add directories to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(submission_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HiggsML.visualization as visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Submission Model\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: receives train set and systematics class as input\n",
    "- `fit`: can be used for training\n",
    "- `predict`: receives one test set and outputs a dictionary with the following keys\n",
    "    - `mu_hat` : predicted mu $\\hat{\\mu}$\n",
    "    - `delta_mu_hat`: $\\Delta{\\hat{\\mu}}$ bound for $\\mu$\n",
    "    - `p16`: 16th percentile\n",
    "    - `p84`: 84th percentile\n",
    "\n",
    "In this example code, the `Model` class implements a basic model with 2 different model trained to predict the class label. \n",
    "\n",
    "* 1 XGBoost BDT ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/boosted_decision_tree.py) )\n",
    "* 2 Tebsorflow NN  ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/neural_network.py) )\n",
    "\n",
    "The feature engineering is in where you can include derived quantities and decide which feature should be needed. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/feature_engineering.py) ) \n",
    "\n",
    "the statistical analysis part is where yoiu write the mu finding calculation using the output of the classifier. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/statistical_analysis.py) ) \n",
    "\n",
    "If running in Collab, click the folder icon in the left sidebar to open the file browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### ⚠️ Note:\n",
    "The data used here is a small sample data is for demonstration only to get a view of what the data looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`USE_PUBLIC_DATASET` determines whether to use a public dataset provided for the participants or use a small sample datafor quick execution of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PUBLIC_DATASET = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`USE_PUBLIC_DATASET` determines whether to use a public dataset provided for the participants or use a small subset of the data for quick execution of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PUBLIC_DATASET:\n",
    "    from HiggsML.datasets import BlackSwan_public_dataset as public_dataset\n",
    "    data = public_dataset()\n",
    "else:\n",
    "    data = Data(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function loads the downloaded data in the public_data folder or downloads the data from codabench using `wget` in the absence of the downloaded data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train set\n",
    "data.load_train_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test sets\n",
    "data.load_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Visualize\n",
    "***\n",
    "- Visualize Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize = visualization.Dataset_visualise(\n",
    "    data_set=data.get_train_set(),\n",
    "    columns=[\n",
    "        \"PRI_jet_leading_pt\",\n",
    "        \"PRI_met\",\n",
    "        \"PRI_lep_phi\",\n",
    "        \"PRI_had_eta\",\n",
    "    ],\n",
    "    name=\"Train Set\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data summary\n",
    "train_visualize.examine_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data summary\n",
    "train_visualize.histogram_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize.stacked_histogram(\"PRI_had_eta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data summary\n",
    "train_visualize.pair_plots(sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_train_data = data.get_syst_train_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plots of train set with systematics\n",
    "train_visualize.pair_plots_syst(syst_train_data[\"data\"], sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraped_data = data.generate_psuedo_exp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data summary\n",
    "train_visualize.examine_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from HiggsML.ingestion import Ingestion\n",
    "\n",
    "ingestion = Ingestion(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize submission\n",
    "ingestion.init_submission(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit submission\n",
    "ingestion.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load test set\n",
    "data.load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict submission\n",
    "ingestion.predict_submission(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion.compute_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save result\n",
    "ingestion.save_result(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "1. Compute Scores\n",
    "2. Visualize Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.score import Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Score\n",
    "score = Scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir)\n",
    "score.load_ingestion_results(prediction_dir = output_dir, score_dir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Score\n",
    "score.compute_scores(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scatter plot of ground truth mu and predicted mu\n",
    "visualization.visualize_scatter(ingestion_result_dict=ingestion.results_dict, \n",
    "                  ground_truth_mus=test_settings[\"ground_truth_mus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "from contextlib import closing\n",
    "# -------------------------------------\n",
    "# Zip files\n",
    "# -------------------------------------\n",
    "def zipdir(archivename, basedir):\n",
    "    '''Zip directory, from J.F. Sebastian http://stackoverflow.com/'''\n",
    "    assert os.path.isdir(basedir)\n",
    "    with closing(ZipFile(archivename, \"w\", ZIP_DEFLATED)) as z:\n",
    "        for root, dirs, files in os.walk(basedir):\n",
    "            # NOTE: ignore empty directories\n",
    "            for fn in files:\n",
    "                if fn[-4:] != '.zip' and fn != '.DS_Store':\n",
    "                    absfn = os.path.join(root, fn)\n",
    "                    zfn = absfn[len(basedir):]  # XXX: relative path\n",
    "                    z.write(absfn, zfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare the submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "code_submission = 'BlackSwan-code_submission_' + the_date + '.zip'\n",
    "zipdir(code_submission, submission_dir)\n",
    "print(\"Submit : \" + code_submission + \" to the competition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9e001b0608738f9411416229c98988c04b997dc526fb61c5e4e084e768e3249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
